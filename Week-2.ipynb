{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c7eef6-7ceb-49a3-be94-7ca32f5c5a3f",
   "metadata": {},
   "source": [
    "Example-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa35c56-96cd-486f-ac48-f8486afde527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f481b920-6a73-4577-9896-5d581e4934dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor(3.5000, requires_grad=True)\n",
      "Y: tensor(12.2500, grad_fn=<MulBackward0>)\n",
      "Z: tensor(27.5000, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(3.5,requires_grad=True)\n",
    "y=x*x\n",
    "z=2*y+3\n",
    "print(\"X:\",x)\n",
    "print(\"Y:\",y)\n",
    "print(\"Z:\",z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26841436-8925-437c-b61a-0835f908d002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\n",
      "Gradient at X: tensor(14.)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(\"....\")\n",
    "print(\"Gradient at X:\",x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e99e5e4-de60-40d7-bc87-6e718d30478c",
   "metadata": {},
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95e7ae7e-999c-4779-84a8-f1326d9ba9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_manual(a,b):\n",
    "    x=2*a+3*b\n",
    "    y=5*a*a+3*b*b*b\n",
    "    z=2*x+3*y\n",
    "    dzdx=2\n",
    "    dzdy=3\n",
    "    dxda=2\n",
    "    dyda=10*a\n",
    "    dzda=dzdx*dxda+dzdy*dyda\n",
    "    return dzda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a615251-d1ae-48e5-9e80-70323f29c607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter A: 5\n",
      "Enter B: 5\n"
     ]
    }
   ],
   "source": [
    "a1=float(input(\"Enter A:\"))\n",
    "b2=float(input(\"Enter B:\"))\n",
    "a=torch.tensor([a1],requires_grad=True)\n",
    "b=torch.tensor([b2],requires_grad=True)\n",
    "c=grad_manual(a,b)\n",
    "x=2*a+3*b\n",
    "y=5*a*a+3*b*b*b\n",
    "z=2*x+3*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc91061c-b33d-4010-a32f-0e2ece253bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b53989-ec04-4407-9f52-44746d1a6ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\n",
      "Gradient at X using autograd: tensor([154.])\n",
      "Gradient at X using Manual: tensor([154.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"....\")\n",
    "print(\"Gradient at X using autograd:\",a.grad)\n",
    "print(\"Gradient at X using Manual:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd67b4e-9810-410f-8c20-3dfcec27630e",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4664ecab-4890-4556-b787-b6bd60bf4aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_manual(w,x,b):\n",
    "    dadv=1\n",
    "    dvdu=1\n",
    "    dvdb=1\n",
    "    dudw=x\n",
    "    dadw=dadv*dvdu*dudw\n",
    "    return dadw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b2e433e-ae26-4f8b-bc82-b0ed6c6463e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter X: 3\n",
      "Enter W: 4\n",
      "Enter B: 5\n"
     ]
    }
   ],
   "source": [
    "a1=float(input(\"Enter X:\"))\n",
    "b2=float(input(\"Enter W:\"))\n",
    "b1=float(input(\"Enter B:\"))\n",
    "X=torch.tensor([a1],requires_grad=True)\n",
    "W=torch.tensor([b2],requires_grad=True)\n",
    "B=torch.tensor([b1],requires_grad=True)\n",
    "u=W*X\n",
    "v=u+B\n",
    "a=max(v,0)\n",
    "if(a!=0):\n",
    "    c=grad_manual(W,X,B)\n",
    "else:\n",
    "    c=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "323c6dae-fcc7-4028-a576-a5a673f238ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a8b0b51-8f5f-439d-b7a7-0b52ee63d5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\n",
      "Gradient at W using autograd: tensor([3.])\n",
      "Gradient at W using Manual: tensor([3.], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"....\")\n",
    "print(\"Gradient at W using autograd:\",W.grad)\n",
    "print(\"Gradient at W using Manual:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426487bd-4390-4593-816b-71a08892ab0e",
   "metadata": {},
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56d9bb62-38f6-4279-ba7d-24f9c07c1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_manual(w,x,b):\n",
    "    dadv=torch.exp(-v)/((1+torch.exp(-v))**2)\n",
    "    dvdu=1\n",
    "    dvdb=1\n",
    "    dudw=x\n",
    "    dadw=dadv*dvdu*dudw\n",
    "    return dadw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7cd4434-def8-4a17-8122-c9bb4434bdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter X: 3\n",
      "Enter W: 4\n",
      "Enter B: 5\n"
     ]
    }
   ],
   "source": [
    "a1=float(input(\"Enter X:\"))\n",
    "b2=float(input(\"Enter W:\"))\n",
    "b1=float(input(\"Enter B:\"))\n",
    "X=torch.tensor([a1],requires_grad=True)\n",
    "W=torch.tensor([b2],requires_grad=True)\n",
    "B=torch.tensor([b1],requires_grad=True)\n",
    "u=W*X\n",
    "v=u+B\n",
    "a=1/(1+torch.exp(-v))\n",
    "c=grad_manual(W,X,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8a34411-4a6b-4362-aa57-c94839a3f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24013107-7e93-43a6-be25-9b7920f04446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\n",
      "Gradient at W using autograd: tensor([1.2420e-07])\n",
      "Gradient at W using Manual: tensor([1.2420e-07], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"....\")\n",
    "print(\"Gradient at W using autograd:\",W.grad)\n",
    "print(\"Gradient at W using Manual:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f4f512-ff6f-4dba-ae4d-9c02f5db6f50",
   "metadata": {},
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd59c3ae-d2f1-4686-84ff-3f90360eaffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def grad_manual(x):\n",
    "    c=torch.exp(-x**2-2*x-torch.sin(x))*(-2*x-2-torch.cos(x))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "264f9124-bbed-4e90-8faf-a899484130f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter X: 3\n"
     ]
    }
   ],
   "source": [
    "b1=float(input(\"Enter X:\"))\n",
    "x=torch.tensor([b1],requires_grad=True)\n",
    "f=torch.exp(-x**2-2*x-torch.sin(x))\n",
    "c=grad_manual(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d722eb40-1fee-4e38-abfe-291dd29d6d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1784bf30-e764-49ef-ad49-cdfda20e35bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\n",
      "Gradient at W using autograd: tensor([-1.8621e-06])\n",
      "Gradient at W using Manual: tensor([-1.8621e-06], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"....\")\n",
    "print(\"Gradient at W using autograd:\",x.grad)\n",
    "print(\"Gradient at W using Manual:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a4059f-021a-493e-b553-092a0225aba8",
   "metadata": {},
   "source": [
    "Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0616745f-ec47-49fa-9dd3-760945c88059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_manual(x):\n",
    "    c=32*x**3+9*x**2+14*x+6\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62c85c0a-293e-407b-9a23-f622369f0253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter X: 2\n"
     ]
    }
   ],
   "source": [
    "b1=float(input(\"Enter X:\"))\n",
    "x=torch.tensor([b1],requires_grad=True)\n",
    "f=8*x**4+3*x**3+7*x**2+6*x+3\n",
    "c=grad_manual(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ddc09efb-1456-4b11-a27f-5a3e4f3a4e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "447dacc1-476d-48ed-99ed-f5a12c3bc486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\n",
      "Gradient at W using autograd: tensor([326.])\n",
      "Gradient at W using Manual: tensor([326.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"....\")\n",
    "print(\"Gradient at W using autograd:\",x.grad)\n",
    "print(\"Gradient at W using Manual:\",c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4bcc35-5579-4402-ae41-e77a07c68c5e",
   "metadata": {},
   "source": [
    "Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a31f3c19-dab9-4981-b342-850680aeed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_manual(x,y,z):\n",
    "    b=torch.sin(y)\n",
    "    a=2*x\n",
    "    c=a/b\n",
    "    d=c*z\n",
    "    e=torch.log(d+1)\n",
    "    f=torch.tanh(e)\n",
    "    print(\"a=\",a,\"\\nb=\",b,\"\\nc=\",c,\"\\nd=\",d,\"\\ne=\",e,\"\\nf=\",f)\n",
    "    df=(1-torch.tanh(e)**2)*(1/(d+1))*z*(1/b)*2\n",
    "    df1=(1-torch.tanh(e)**2)*(1/(d+1))*z*(-a/(b**2))*torch.cos(y)\n",
    "    return df,df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "965023e5-ef7c-44c8-a608-4f85b1396c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter X: 2\n",
      "Enter Y: 3\n",
      "Enter Z: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= tensor([4.], grad_fn=<MulBackward0>) \n",
      "b= tensor([0.1411], grad_fn=<SinBackward0>) \n",
      "c= tensor([28.3447], grad_fn=<DivBackward0>) \n",
      "d= tensor([113.3787], grad_fn=<MulBackward0>) \n",
      "e= tensor([4.7395], grad_fn=<LogBackward0>) \n",
      "f= tensor([0.9998], grad_fn=<TanhBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a1=float(input(\"Enter X:\"))\n",
    "b2=float(input(\"Enter Y:\"))\n",
    "b1=float(input(\"Enter Z:\"))\n",
    "x=torch.tensor([a1],requires_grad=True)\n",
    "y=torch.tensor([b2],requires_grad=True)\n",
    "z=torch.tensor([b1],requires_grad=True)\n",
    "b=torch.sin(y)\n",
    "a=2*x\n",
    "c=a/b\n",
    "d=c*z\n",
    "e=torch.log(d+1)\n",
    "f=torch.tanh(e)\n",
    "c,c1=grad_manual(x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "96053852-62b2-41da-b89a-231ff8f8e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "25db27dc-c405-43a7-9f76-ab9d8a66133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\n",
      "Gradient at X using autograd: tensor([0.0002])\n",
      "Gradient at Y using autograd: tensor([0.0021])\n",
      "Gradient at x,y using Manual: tensor([0.0002], grad_fn=<MulBackward0>) \n",
      "and\n",
      " tensor([0.0021], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"....\")\n",
    "print(\"Gradient at X using autograd:\",x.grad)\n",
    "print(\"Gradient at Y using autograd:\",y.grad)\n",
    "print(\"Gradient at x,y using Manual:\",c,\"\\nand\\n\",c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c781b-d3f1-4915-82c6-286c41014a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
